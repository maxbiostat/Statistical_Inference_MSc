\documentclass[a4paper,10pt, notitlepage]{report}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{cancel}
\usepackage{mathtools}
\usepackage[portuguese]{babel}

%%%%%%%%%%%%%%%%%%%% Notation stuff
\newcommand{\pr}{\operatorname{Pr}} %% probability
\newcommand{\vr}{\operatorname{Var}} %% variance
\newcommand{\rs}{X_1, X_2, \ldots, X_n} %%  random sample
\newcommand{\ods}{X_{(1)}, X_{(2)}, \ldots, X_{(n)} } %%  ordered sample
\newcommand{\irs}{X_1, X_2, \ldots} %% infinite random sample
\newcommand{\rsd}{x_1, x_2, \ldots, x_n} %%  random sample, realised
\newcommand{\bX}{\boldsymbol{X}} %%  random sample, contracted form (bold)
\newcommand{\bx}{\boldsymbol{x}} %%  random sample, realised, contracted form (bold)
\newcommand{\bT}{\boldsymbol{T}} %%  Statistic, vector form (bold)
\newcommand{\bt}{\boldsymbol{t}} %%  Statistic, realised, vector form (bold)
\newcommand{\emv}{\hat{\theta}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand{\rpl}{\mathbb{R}_+}


% Title Page
\title{Exercícios: Métodos de Estimação (Momentos, Máxima Verossimilhança)}
\author{Disciplina: Inferência Estatística (MSc) \\ Instrutor: Luiz Carvalho \\ Monitor: Isaque Pim}
\date{Novembro/2023}

\begin{document}
\maketitle

\paragraph{Motivação:} Em aula vimos os métodos de momentos, de mínimos quadrados e de máxima verossimilhança para obter estimativas (e estimadores!) de parâmetros e quantidades de interesse. Nesta lista você vai praticar encontrar esses estimadores e entender suas propriedades.

\paragraph{Notação:} Como convenção adotamos $\mathbb{R} = (-\infty, \infty)$, $\rpl = (0, \infty)$ e $\mathbb{N} = \{1, 2, \ldots \}$.

\paragraph{Dos livros-texto:}

\begin{itemize}
    \item[a)] KN, Ch9: 17a, 21a, 21b.
    \item[b)] CB, Ch7: 7.1, 7.2\footnote{Se precisar, peça ajuda ao monitor para a parte computacional.}, 7.6, 7.11, 7.12, 7.19, 7.37, 7.38.
\end{itemize}


\paragraph{Extra:}

\begin{enumerate}  
    \item \textbf{O equilíbrio de Hardy-Weinberg}\footnote{Godfrey Harold Hardy (1877-1947) foi um grande matemático Britânico famoso por dizer que seu trabalho não tinha a menor relevância para a vida real. Hardy estava errado, é claro. Wilhelm Weinberg (1862-1937) foi um médico alemão que descobriu o princípio do equilíbrio genético independentemente (e antes) de Hardy.}
    Considere uma amostra de uma população em \underline{equilíbrio genético} com respeito a um único gene que tem dois alelos ($A$ e $a$).
   Há três configurações possíveis, chamadas genótipos:
    \begin{itemize}
        \item Homozigoto recessivo: $aa$;
        \item Heterozigoto: $Aa$;
        \item Homozigoto dominante: $AA$.
    \end{itemize}
     Se assumirmos que os três genótipos são identificáveis, podemos supor que os três tipos de indivíduos occorem na população seguindo o \textit{equilíbrio de Hardy-Weinberg}.
     Seja $X$ a variável aleatória que guarda o genótipo do indivíduo.
     Então podemos escrever as probabilidades
     \begin{align*}
         \pr(X = aa) &:= p_1 = \theta^2,\\
         \pr(X = Aa) &:= p_2 = 2\theta(1-\theta),\\
         \pr(X = AA) &:= p_3 = (1-\theta)^2,
     \end{align*}
     para $\theta \in (0, 1)$.
     Tome uma amostra de tamanho $n$ da população e seja $N_i$ o número de indivíduos do genótipo $i$ amostrados, para $i = 1, 2, 3$, de sorte que $n = \sum_{i=1}^3 N_i$.
     \begin{enumerate}
         \item Deduza a distribuição de $\boldsymbol{N} = (N_1, N_2, N_3)$;
         \item Mostre como estimar $\theta$ por máxima verossimilhança;
         \item Discuta como estimar $\theta$ pelo método dos momentos;
         \item Avalie $\delta_s = N_1/n + N_2/n$ como estimador de $\theta$ em relação aos anteriores.
     \end{enumerate}
    \item Tome $n\geq 2$ e $\rs$ amostra aleatória de uma distribuição com densidade comum com respeito a Lebesgue
    \begin{equation*}
        p_\theta(x) = \frac{\theta}{x^2} \mathbb{I}\left(x \in [\theta, \infty)\right),
    \end{equation*}
    com $\theta \in \mathbb{R}_+$.
    \begin{itemize}
        \item Compute o EMV de $\theta$.
        Este estimador é consistente?
        Podemos aplicar os teoremas discutidos em aula?
        \item Compute o viés do estimador de $g(\theta) = E_\theta[X^{-1}]$ como função do tamanho de amostra $n$ e discuta o que acontece quando $n \to \infty$.
    \end{itemize}
    \item  \textbf{PhD}: Tome $\mathcal{P}$ família dominada com densidade com respeito à medida de contagem em $\mathbb{N}$:
    \begin{equation*}
        p_\theta(x) = \frac{\theta}{x^{\theta + 1}} \mathbb{I}(x \geq 1),
    \end{equation*}
    para $x \in \mathbb{N}$ e $\theta > 1$.
    Encontre estimadores de (i) momentos e (ii) máxima verossimilhança para $\theta$ e compute (e compare) suas variâncias.
    Utilize métodos de Monte Carlo, se precisar. 
    \item \textbf{PhD}:  Seja $\rs$ uma amostra aleatória de uma família dominada, cuja densidade comum (com respeito a Lebesgue) é  $$ f_\theta(x) = \frac{\exp(-|x-\theta|)}{2}\mathbb{I}(x \in \mathbb{R}), \: \theta \in \mathbb{R}.$$
    Suponha que $n$ é par e encontre o estimator de máxima verossimilhança para $g(\theta) = \sin(\theta)/\theta$.
    Que peculiaridades tem esse estimador?
    
    \textbf{Dica:} Considere escrever a função de verossimilhança em termos da função sinal:
    \begin{equation*}
\operatorname{sgn}(x)=
\begin{cases}
-1,\quad x < 0,\\
\:\:\:0, \quad x = 0,\\
\:\:\:1, \quad x > 0.
\end{cases}
    \end{equation*}
    para $x \in \mathbb{R}$.
\end{enumerate}
% \newpage



% \bibliographystyle{apalike}
% \bibliography{refs}

\end{document}          

